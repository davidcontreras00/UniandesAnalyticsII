Dentro de los algoritmos de árbol de decisión más destacados se encuentran: ID3, C4.5, ACR, CHAID, MARS, árboles de inferencia condicional.
ID3 (Iterative Dichotomiser 3): Utilizado en inteligencia artificial que usa como medida para sus divisiones la medida de entropía (ganancia o proporción de ganancia). Su uso se engloba en la búsqueda de hipótesis o reglas en él, dado un conjunto de ejemplos que debe estar conformado por tuplas de valores denominados atributos, en el que el atributo a clasificar es el objetivo, el cual es dicotómico (si-no, positivo-negativo, válido-inválido, etc.).
C4.5: Es una extensión del algoritmo ID3, se hacen básicamente ajustes en las mejoras de las podas, ajuste de ruido, características a variables continuas. 
ACR: Se refiere a los árboles de clasificación y regresión. Clasificación es cuando el resultado predicho es la clase a la que pertenecen los datos (predice variables categóricas) y regresión (variables numéricas) cuando el resultado predicho se puede considerar un número real (por ejemplo, el precio de una casa, o el número de días de estancia de un paciente en un hospital) (predice variables categóricas).
CHAID (Detector automático de Chi-cuadrado de interacción): Propuesto por (Kass 1980) es más utilizado en estudios de marketing y es un algoritmo recursivo de clasificación no binario, sin embargo, tiene importantes limitaciones ya que puede no capturar todas las interacciones entre las variables predictoras y la objetivo.
MARS (Multivariate Adaptive Regression Splines): Consiste en reemplazar la división discontinua en un nodo con una transición modelada por un par de líneas directas. Al final del proceso de construcción del modelo, las líneas directas en cada nodo son reemplazadas con una función libre de obstáculos.
Algunos de los casos en los cuales se aplica el uso de árboles de decisión, son los siguientes:
Segmentación: Identifica miembros de una clase concreta.  
Estratificación: Asigna casos a una categoría, por ejemplo, grupos de alto, medio y bajo riesgo. 
Predicción: Crea reglas y las utiliza para hacer predicciones.
Reducción de datos y clasificación de variables: Selecciona un subconjunto útil de predictores a partir de un gran conjunto de variables para utilizarlo en la creación de un modelo paramétrico formal.


http://simposioestadistica.unal.edu.co/fileadmin/content/eventos/simposioestadistica/documentos/memorias/Memorias_2016/Comunicaciones/Mineria_de_Datos/Aprendizaje_Arboles_WekaRapidMinerSPSS_Moreno_Salazar_Vicente___Galindo.pdf
https://es.wikipedia.org/wiki/Aprendizaje_basado_en_%C3%A1rboles_de_decisi%C3%B3n
